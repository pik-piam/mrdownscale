---
title: "How to downscale data from a new model"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to downscale data from a new model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## starting point
You have regional (i.e non-gridded) land use data produced by an integrated assessment
model (we use "CoolNewModel" as placeholder name here) that should be harmonized and
downscaled using LUH3 as historical high resolution reference dataset.

This vignette describes how to modify mrdownscale to process CoolNewModel
land data, but does not cover harmonization or downscaling of nonland variables
like fertilizer, even though mrdownscale is capable of handling those
(implemented for MAgPIE). If you have questions or run into trouble feel
free to contact the mrdownscale developers (mail address in DESCRIPTION file).

## requirements/preparation

### files
- CoolNewModel dataset file (in a format R can read)
- region mapping (which country/gridcell belongs to which region?)
- variable mapping (mapping your variables to fine-grained reference variables,
see csv files in `inst/extdata/referenceMappings`)

### software setup
- install R: https://cran.rstudio.com/
- open R and find your home directory with
```{r, echo = TRUE, eval = FALSE}
normalizePath("~")
```
- in that folder create/edit a file called ".Rprofile" and put in the
following, so
  - you can install mrdownscale from the piam repository
(it's not on the central R package repo called "CRAN")
  - madrat knows where to store its data:
```{r, echo = TRUE, eval = FALSE}
options(repos = c(runiverse = "https://pik-piam.r-universe.dev",
                  CRAN = "https://cran.rstudio.com/"))
options(MADRAT_MAINFOLDER = file.path(normalizePath("~"), "madrat_mainfolder"))
```

- start a fresh R session and install mrdownscale incl. dependencies, pkgload for development:
```{r, echo = TRUE, eval = FALSE}
install.packages(c("mrdownscale", "pkgload"))
```

## integrating into mrdownscale
Currently mrdownscale itself needs to be modified to integrate a new model.
To do so, we recommend creating a fork of the
[mrdownscale repo](https://github.com/pik-piam/mrdownscale), then clone
your fork to a folder on your local machine. Apply the changes explained
in the following sections in that folder. To test your changes, always start
a fresh R session (!) in that folder and run `pkgload::load_all()` to
load your local mrdownscale directly from the source files.

To get an overview what changes are needed check
[this PR](https://github.com/pik-piam/mrdownscale/pull/38) which enabled
mrdownscale to process data from the COFFEE model.

### reference mapping
A mapping from CoolNewModel variables to fine-grained reference variables
is needed in order to map from CoolNewModel variables to the variables
of any of the supported target datasets. In case CoolNewModel variables
do not cover the entire land area, e.g. if urban is missing, map these
to a variable called "rest". Put your mapping csv file into
inst/extdata/referenceMappings. Check the reference mapping for COFFEE
for an example (that file is also located in inst/extdata/referenceMappings):

```{r, echo = TRUE}
cat(readLines(system.file("extdata/referenceMappings/coffee.csv",
                          package = "mrdownscale"), n = 30), sep = "\n")
```


Some more details on how the variable mapping works:
```{r, echo = TRUE}
?mrdownscale:::calcLandInputRecategorized
```

### read function
mrdownscale uses the madrat framework, if you want to learn more about madrat check this
[vignette](https://pik-piam.r-universe.dev/articles/madrat/madrat.html). Reading that
vignette should not be necessary to follow this tutorial though.

Before you can read your data via madrat your files need to be put into the
expected place:
```{r, echo = TRUE}
madrat::getConfig("sourcefolder", verbose = FALSE)
```
In this folder there's a subfolder for each dataset that can be read via
madrat. Create a new folder called CoolNewModel there and put your data
file and the region mapping file into it.


Write a function that reads in your data (`subtype = "data"`) and your
resolution mapping (`subtype = "resolutionMapping"`) as a data frame. The
function name must start with `read` and the rest of the function name must
match the name of the source folder you created earlier, so
call it `readCoolNewModel`. Here's an example read function:
```{r, echo = TRUE}
mrdownscale:::readWITCH
```

To test your source folder and read function setup, start a new R session and run the following:
```{r, echo = TRUE, eval = FALSE}
pkgload::load_all("/path/to/mrdownscale")
x <- readSource("CoolNewModel", subtype = "data")
print(x)
map <- readSource("CoolNewModel", subtype = "resolutionMapping")
print(map)
```
`readCoolNewModel` is not (and should never be) called directly,
but instead indirectly via `readSource` which will, among other things,
change the working directory to the corresponding source folder
first and also store results into the cache and load them from there if
nothing relevant changed.


### calcLandInput
Add another `if` branch in `R/calcLandInput.R`:
```{r, echo = TRUE, eval = FALSE}
if (input == "magpie") {
  # ...
} else if (input == "CoolNewModel") {
  x <- readSource("CoolNewModel")
  # here
}
```
Here is the place to fix/adapt your data to what mrdownscale expects at the
end of calcLandInput (consistency checks):
- no NA/missing values
- values >= 0
- non-overlapping categories (i.e. not forest & primary forest & secondary forest)
- total area (sum over all variables) is constant over time
(add "rest" variable, in case some variables e.g. urban are missing)
- convert to magclass/magpie object (`as.magpie(x)`)
- variable names must match those in reference mapping

### calcResolutionMapping
Add another `if` branch in `R/calcResolutionMapping.R`:
```{r, echo = TRUE, eval = FALSE}
if (input == "magpie") {
  # ...
} else if (input == "CoolNewModel") {
  x <- readSource("CoolNewModel", subtype = "resolutionMapping")
  # here
}
```
Based on your resolution mapping, create mapping between regional level and
target grid level. In case you have a mapping from country to region you can
use the existing magpie mapping which includes a mapping from countries to
the target grid level. This was done for COFFEE, see the `input == "coffee"`
if-branch in `R/calcResolutionMapping.R`.

### toolLandCategoriesMapping
Put your variable mapping (mapping your variables to fine-grained reference
variables) next to the other csv files in `inst/extdata/referenceMappings`.
Add CoolNewModel to the if-else statement in `R/toolLandCategoriesMapping.R`
just like the other models.

## running harmonization
To calculate harmonized data (on model-native/regional resolution) and write it to a csv file:
```{r, echo = TRUE, eval = FALSE}
harmonized <- calcOutput("LandHarmonized", input = "CoolNewModel", target = "luh3",
                         harmonizationPeriod = c(2020, 2050), harmonization = "fadeForest")
write.magpie(harmonized, "harmonized.csv")
```

## running downscaling / the full pipeline
To run the full pipeline including harmonization and downscaling, and then unpack the resulting tgz archive:
```{r, echo = TRUE, eval = FALSE}
pathToTgz <- retrieveData("SCENARIOMIP", input = "CoolNewModel")
untar(pathToTgz)
```
After running this there should be netcdf files (`.nc`) in your working
directory that contain harmonized and downscaled data on grid resolution.
